{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2587f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import from_bounds\n",
    "from rasterio.warp import reproject, Resampling\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.plot import show\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from scipy import ndimage\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up directories\n",
    "os.makedirs('output', exist_ok=True)\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('data', exist_ok=True)\n",
    "\n",
    "# Configuration will be set by user choice\n",
    "MODEL_PATH = 'models/fire_prediction_model.pkl'\n",
    "FORCE_RETRAIN = False\n",
    "\n",
    "print(\"üì¶ Libraries imported successfully!\")\n",
    "print(\"üìÅ Directories created/verified!\")\n",
    "print(\"‚öôÔ∏è  System ready for user input...\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0027bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî• FOREST FIRE PREDICTION SYSTEM üî•\n",
    "print(\"=\" * 60)\n",
    "print(\"üî• WELCOME TO FOREST FIRE PREDICTION SYSTEM üî•\")\n",
    "print(\"=\" * 60)\n",
    "print()\n",
    "\n",
    "# Simple user choice system\n",
    "print(\"üìã PLEASE SELECT AN OPTION:\")\n",
    "print(\"1Ô∏è‚É£  Train New Model (Will take time but gives fresh results)\")\n",
    "print(\"2Ô∏è‚É£  Use Existing Model (Fast - loads pre-trained model)\")\n",
    "print()\n",
    "\n",
    "# Get user choice\n",
    "while True:\n",
    "    try:\n",
    "        user_option = input(\"Enter your choice (1 or 2): \").strip()\n",
    "        if user_option == \"1\":\n",
    "            RETRAIN_MODEL = True\n",
    "            print(\"‚úÖ You selected: TRAIN NEW MODEL\")\n",
    "            print(\"üîÑ The system will train a new model with current data\")\n",
    "            break\n",
    "        elif user_option == \"2\":\n",
    "            RETRAIN_MODEL = False\n",
    "            print(\"‚úÖ You selected: USE EXISTING MODEL\")\n",
    "            print(\"üìÇ The system will load existing model (if available)\")\n",
    "            break\n",
    "        else:\n",
    "            print(\"‚ùå Invalid choice! Please enter 1 or 2\")\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n‚ö†Ô∏è  Using default option: USE EXISTING MODEL\")\n",
    "        RETRAIN_MODEL = False\n",
    "        break\n",
    "    except:\n",
    "        print(\"‚ùå Please enter 1 or 2\")\n",
    "\n",
    "print()\n",
    "print(\"üöÄ Starting the system...\")\n",
    "print(\"=\" * 60)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae95af6",
   "metadata": {},
   "source": [
    "# üî• Forest Fire Prediction & Spread Simulation\n",
    "\n",
    "## üöÄ How to Use This System\n",
    "\n",
    "When you run the first cell, you'll be prompted to choose:\n",
    "\n",
    "### **Option 1: Train New Model**\n",
    "- ‚úÖ **Fresh training** with current data\n",
    "- ‚úÖ **Most accurate** results\n",
    "- ‚úÖ **Recommended for first-time users**\n",
    "- ‚ö†Ô∏è **Takes time** (several minutes)\n",
    "\n",
    "### **Option 2: Use Existing Model**\n",
    "- ‚úÖ **Fast execution** (instant results)\n",
    "- ‚úÖ **Uses pre-trained model**\n",
    "- ‚úÖ **Good for quick analysis**\n",
    "- ‚ö†Ô∏è **Requires existing model** (will train if none found)\n",
    "\n",
    "---\n",
    "\n",
    "## üìã Quick Start\n",
    "\n",
    "1. **Run the first cell** - You'll see a prompt asking for your choice\n",
    "2. **Enter 1** to train a new model OR **Enter 2** to use existing model\n",
    "3. **Run all cells** to execute the complete pipeline\n",
    "4. **Check the output folder** for results\n",
    "\n",
    "---\n",
    "\n",
    "## üìÅ Output Files\n",
    "\n",
    "The system generates:\n",
    "- Fire risk prediction maps\n",
    "- Fire spread simulations\n",
    "- Model performance metrics\n",
    "- Comprehensive visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36cfdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasterProcessor:\n",
    "    def __init__(self, target_resolution=30):\n",
    "        self.target_resolution = target_resolution\n",
    "        self.raster_files = {\n",
    "            'temperature': 'data/temperature.tif',\n",
    "            'humidity': 'data/humidity.tif',\n",
    "            'wind_speed': 'data/wind_speed.tif',\n",
    "            'wind_dir': 'data/wind_dir.tif',\n",
    "            'rainfall': 'data/rainfall.tif',\n",
    "            'dem': 'data/dem.tif',\n",
    "            'lulc': 'data/lulc.tif',\n",
    "            'roads': 'data/roads.tif',\n",
    "            'settlements': 'data/settlements.tif',\n",
    "            'fire_labels': 'data/fire_labels.tif'\n",
    "        }\n",
    "        \n",
    "    def load_raster(self, filepath):\n",
    "        \"\"\"Load raster data using rasterio\"\"\"\n",
    "        try:\n",
    "            with rasterio.open(filepath) as src:\n",
    "                data = src.read(1)\n",
    "                transform = src.transform\n",
    "                crs = src.crs\n",
    "                profile = src.profile\n",
    "            return data, transform, crs, profile\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {filepath}: {e}\")\n",
    "            return None, None, None, None\n",
    "    \n",
    "    def resample_raster(self, data, transform, profile, target_resolution):\n",
    "        \"\"\"Resample raster to target resolution\"\"\"\n",
    "        original_res = abs(transform.a)\n",
    "        \n",
    "        if abs(original_res - target_resolution) < 1e-6:\n",
    "            return data, transform, profile\n",
    "        \n",
    "        scale_factor = original_res / target_resolution\n",
    "        \n",
    "        new_height = max(1, int(data.shape[0] * scale_factor))\n",
    "        new_width = max(1, int(data.shape[1] * scale_factor))\n",
    "        \n",
    "        # If dimensions are too small, just return original data\n",
    "        if new_height <= 1 or new_width <= 1:\n",
    "            return data, transform, profile\n",
    "        \n",
    "        resampled_data = np.zeros((new_height, new_width))\n",
    "        \n",
    "        dst_transform = rasterio.transform.from_bounds(\n",
    "            transform.c, transform.f + transform.e * data.shape[0],\n",
    "            transform.c + transform.a * data.shape[1], transform.f,\n",
    "            new_width, new_height\n",
    "        )\n",
    "        \n",
    "        reproject(\n",
    "            source=data,\n",
    "            destination=resampled_data,\n",
    "            src_transform=transform,\n",
    "            src_crs=profile['crs'],\n",
    "            dst_transform=dst_transform,\n",
    "            dst_crs=profile['crs'],\n",
    "            resampling=Resampling.bilinear\n",
    "        )\n",
    "        \n",
    "        profile.update({\n",
    "            'height': new_height,\n",
    "            'width': new_width,\n",
    "            'transform': dst_transform\n",
    "        })\n",
    "        \n",
    "        return resampled_data, dst_transform, profile\n",
    "    \n",
    "    def calculate_slope_aspect(self, dem):\n",
    "        \"\"\"Calculate slope and aspect from DEM\"\"\"\n",
    "        grad_x = np.gradient(dem, axis=1)\n",
    "        grad_y = np.gradient(dem, axis=0)\n",
    "        \n",
    "        slope = np.sqrt(grad_x**2 + grad_y**2)\n",
    "        aspect = np.arctan2(grad_y, grad_x)\n",
    "        \n",
    "        return slope, aspect\n",
    "    \n",
    "    def visualize_raster(self, data, title, cmap='viridis'):\n",
    "        \"\"\"Visualize raster data\"\"\"\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        plt.imshow(data, cmap=cmap)\n",
    "        plt.colorbar()\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "\n",
    "processor = RasterProcessor()\n",
    "print(\"RasterProcessor class created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e2d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_data():\n",
    "    \"\"\"Create sample GeoTIFF files for testing\"\"\"\n",
    "    \n",
    "    np.random.seed(42)\n",
    "    height, width = 200, 200\n",
    "    \n",
    "    transform = rasterio.transform.from_bounds(\n",
    "        -120.0, 35.0, -119.0, 36.0, width, height\n",
    "    )\n",
    "    \n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'count': 1,\n",
    "        'dtype': 'float32',\n",
    "        'crs': 'EPSG:4326',\n",
    "        'transform': transform,\n",
    "        'compress': 'lzw'\n",
    "    }\n",
    "    \n",
    "    sample_data = {\n",
    "        'temperature': np.random.uniform(15, 35, (height, width)),\n",
    "        'humidity': np.random.uniform(20, 80, (height, width)),\n",
    "        'wind_speed': np.random.uniform(0, 20, (height, width)),\n",
    "        'wind_dir': np.random.uniform(0, 360, (height, width)),\n",
    "        'rainfall': np.random.uniform(0, 50, (height, width)),\n",
    "        'dem': np.random.uniform(100, 2000, (height, width)),\n",
    "        'lulc': np.random.randint(1, 10, (height, width)),\n",
    "        'roads': np.random.uniform(0, 5000, (height, width)),\n",
    "        'settlements': np.random.uniform(0, 10000, (height, width)),\n",
    "        'fire_labels': np.random.choice([0, 1], (height, width), p=[0.9, 0.1])\n",
    "    }\n",
    "    \n",
    "    for name, data in sample_data.items():\n",
    "        filepath = f'data/{name}.tif'\n",
    "        with rasterio.open(filepath, 'w', **profile) as dst:\n",
    "            dst.write(data.astype(np.float32), 1)\n",
    "    \n",
    "    print(\"Sample data created successfully!\")\n",
    "\n",
    "create_sample_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49422b04",
   "metadata": {},
   "source": [
    "# üéØ Enhanced Dataset Generation\n",
    "\n",
    "This section generates realistic forest fire datasets with proper spatial correlations and environmental patterns that mimic real-world conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24cee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_realistic_dataset(height=500, width=500, num_fire_events=15, seed=42):\n",
    "    \"\"\"\n",
    "    Generate realistic forest fire dataset with spatial correlations and environmental patterns\n",
    "    \n",
    "    Parameters:\n",
    "    - height, width: Dimensions of the raster data\n",
    "    - num_fire_events: Number of fire events to simulate\n",
    "    - seed: Random seed for reproducibility\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Define coordinate bounds (example area in California)\n",
    "    min_lon, max_lon = -121.0, -119.0\n",
    "    min_lat, max_lat = 36.0, 38.0\n",
    "    \n",
    "    transform = rasterio.transform.from_bounds(\n",
    "        min_lon, min_lat, max_lon, max_lat, width, height\n",
    "    )\n",
    "    \n",
    "    profile = {\n",
    "        'driver': 'GTiff',\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'count': 1,\n",
    "        'dtype': 'float32',\n",
    "        'crs': 'EPSG:4326',\n",
    "        'transform': transform,\n",
    "        'compress': 'lzw'\n",
    "    }\n",
    "    \n",
    "    print(f\"Generating {height}x{width} realistic dataset with {num_fire_events} fire events...\")\n",
    "    \n",
    "    # Create coordinate grids\n",
    "    x = np.linspace(0, width-1, width)\n",
    "    y = np.linspace(0, height-1, height)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    \n",
    "    # 1. Generate realistic DEM with mountain ranges\n",
    "    print(\"Generating realistic terrain...\")\n",
    "    dem = np.zeros((height, width))\n",
    "    \n",
    "    # Add multiple mountain ranges\n",
    "    for i in range(3):\n",
    "        center_x = np.random.uniform(width*0.2, width*0.8)\n",
    "        center_y = np.random.uniform(height*0.2, height*0.8)\n",
    "        amplitude = np.random.uniform(800, 1500)\n",
    "        sigma_x = np.random.uniform(width*0.1, width*0.3)\n",
    "        sigma_y = np.random.uniform(height*0.1, height*0.3)\n",
    "        \n",
    "        mountain = amplitude * np.exp(-((X-center_x)**2/(2*sigma_x**2) + (Y-center_y)**2/(2*sigma_y**2)))\n",
    "        dem += mountain\n",
    "    \n",
    "    # Add base elevation and noise\n",
    "    dem += 200 + np.random.normal(0, 50, (height, width))\n",
    "    dem = np.clip(dem, 0, 3000)\n",
    "    \n",
    "    # 2. Generate temperature with elevation correlation\n",
    "    print(\"Generating temperature data...\")\n",
    "    base_temp = 25  # Base temperature at sea level\n",
    "    lapse_rate = 0.006  # Temperature decreases with elevation\n",
    "    temp_seasonal = np.random.normal(0, 5)  # Seasonal variation\n",
    "    \n",
    "    temperature = base_temp - (dem * lapse_rate) + temp_seasonal\n",
    "    # Add spatial variation\n",
    "    temp_gradient_x = np.linspace(-2, 2, width)\n",
    "    temp_gradient_y = np.linspace(-1, 1, height)\n",
    "    temp_grid_x, temp_grid_y = np.meshgrid(temp_gradient_x, temp_gradient_y)\n",
    "    temperature += temp_grid_x + temp_grid_y\n",
    "    \n",
    "    # Add noise\n",
    "    temperature += np.random.normal(0, 2, (height, width))\n",
    "    temperature = np.clip(temperature, -10, 45)\n",
    "    \n",
    "    # 3. Generate humidity (inversely correlated with temperature)\n",
    "    print(\"Generating humidity data...\")\n",
    "    base_humidity = 60\n",
    "    humidity = base_humidity - (temperature - 20) * 1.5\n",
    "    # Add elevation effect (higher humidity at higher elevations)\n",
    "    humidity += (dem - 500) * 0.01\n",
    "    # Add spatial patterns\n",
    "    humidity += np.sin(X/50) * 5 + np.cos(Y/40) * 3\n",
    "    humidity += np.random.normal(0, 5, (height, width))\n",
    "    humidity = np.clip(humidity, 10, 95)\n",
    "    \n",
    "    # 4. Generate wind speed (higher at higher elevations and ridges)\n",
    "    print(\"Generating wind data...\")\n",
    "    # Calculate slope for wind acceleration\n",
    "    grad_x = np.gradient(dem, axis=1)\n",
    "    grad_y = np.gradient(dem, axis=0)\n",
    "    slope = np.sqrt(grad_x**2 + grad_y**2)\n",
    "    \n",
    "    wind_speed = 5 + (dem / 500) * 3 + (slope / 10) * 2\n",
    "    # Add weather patterns\n",
    "    wind_speed += np.sin(X/30) * 2 + np.cos(Y/25) * 1.5\n",
    "    wind_speed += np.random.normal(0, 2, (height, width))\n",
    "    wind_speed = np.clip(wind_speed, 0, 25)\n",
    "    \n",
    "    # 5. Generate wind direction (influenced by topography)\n",
    "    print(\"Generating wind direction...\")\n",
    "    # Base wind direction (prevailing winds)\n",
    "    base_wind_dir = 225  # Southwest winds\n",
    "    wind_dir = np.full((height, width), base_wind_dir, dtype=np.float64)\n",
    "    \n",
    "    # Add topographic influence\n",
    "    aspect = np.arctan2(grad_y, grad_x) * 180 / np.pi\n",
    "    wind_dir += aspect * 0.3  # Terrain channeling effect\n",
    "    \n",
    "    # Add turbulence\n",
    "    wind_dir += np.random.normal(0, 30, (height, width))\n",
    "    wind_dir = wind_dir % 360\n",
    "    \n",
    "    # 6. Generate rainfall (correlated with elevation and humidity)\n",
    "    print(\"Generating rainfall data...\")\n",
    "    # Orographic effect (more rain at higher elevations)\n",
    "    rainfall = 10 + (dem / 200) * 5 + (humidity / 10) * 2\n",
    "    # Add storm patterns\n",
    "    for i in range(3):\n",
    "        storm_x = np.random.uniform(0, width)\n",
    "        storm_y = np.random.uniform(0, height)\n",
    "        storm_intensity = np.random.uniform(15, 40)\n",
    "        storm_radius = np.random.uniform(50, 100)\n",
    "        \n",
    "        storm_dist = np.sqrt((X - storm_x)**2 + (Y - storm_y)**2)\n",
    "        storm_effect = storm_intensity * np.exp(-storm_dist / storm_radius)\n",
    "        rainfall += storm_effect\n",
    "    \n",
    "    rainfall += np.random.normal(0, 3, (height, width))\n",
    "    rainfall = np.clip(rainfall, 0, 100)\n",
    "    \n",
    "    # 7. Generate land use/land cover (elevation and slope dependent)\n",
    "    print(\"Generating land use/land cover...\")\n",
    "    lulc = np.zeros((height, width))\n",
    "    \n",
    "    # Water bodies (low elevation)\n",
    "    water_mask = (dem < 300) & (slope < 2)\n",
    "    lulc[water_mask] = 1\n",
    "    \n",
    "    # Urban areas (moderate elevation, low slope)\n",
    "    urban_mask = (dem > 250) & (dem < 800) & (slope < 5)\n",
    "    urban_prob = 0.05 + (1 / (1 + np.exp(-(dem - 400) / 100))) * 0.1\n",
    "    urban_random = np.random.random((height, width))\n",
    "    urban_areas = urban_mask & (urban_random < urban_prob)\n",
    "    lulc[urban_areas] = 2\n",
    "    \n",
    "    # Agricultural areas (low to moderate elevation, low slope)\n",
    "    ag_mask = (dem > 200) & (dem < 600) & (slope < 10) & (lulc == 0)\n",
    "    ag_prob = 0.15\n",
    "    ag_random = np.random.random((height, width))\n",
    "    ag_areas = ag_mask & (ag_random < ag_prob)\n",
    "    lulc[ag_areas] = 3\n",
    "    \n",
    "    # Grasslands (moderate elevation)\n",
    "    grass_mask = (dem > 300) & (dem < 1200) & (slope < 15) & (lulc == 0)\n",
    "    grass_prob = 0.3\n",
    "    grass_random = np.random.random((height, width))\n",
    "    grass_areas = grass_mask & (grass_random < grass_prob)\n",
    "    lulc[grass_areas] = 4\n",
    "    \n",
    "    # Forest (higher elevation, moderate slope)\n",
    "    forest_mask = (dem > 400) & (dem < 2000) & (slope < 30) & (lulc == 0)\n",
    "    forest_prob = 0.6\n",
    "    forest_random = np.random.random((height, width))\n",
    "    forest_areas = forest_mask & (forest_random < forest_prob)\n",
    "    lulc[forest_areas] = 5\n",
    "    \n",
    "    # Shrubland (higher elevation, steeper slope)\n",
    "    shrub_mask = (dem > 600) & (slope > 10) & (lulc == 0)\n",
    "    lulc[shrub_mask] = 6\n",
    "    \n",
    "    # Bare rock/alpine (very high elevation)\n",
    "    rock_mask = (dem > 2000) | (slope > 35)\n",
    "    lulc[rock_mask] = 7\n",
    "    \n",
    "    # 8. Generate roads (connecting urban areas, following valleys)\n",
    "    print(\"Generating road network...\")\n",
    "    roads = np.full((height, width), 10000.0)  # Initialize with large distances\n",
    "    \n",
    "    # Create main roads connecting urban centers\n",
    "    urban_centers = np.where(lulc == 2)\n",
    "    if len(urban_centers[0]) > 0:\n",
    "        # Select major urban centers\n",
    "        major_centers = []\n",
    "        for i in range(min(5, len(urban_centers[0]))):\n",
    "            idx = np.random.choice(len(urban_centers[0]))\n",
    "            major_centers.append((urban_centers[0][idx], urban_centers[1][idx]))\n",
    "        \n",
    "        # Connect centers with roads\n",
    "        for i in range(len(major_centers)):\n",
    "            for j in range(i+1, len(major_centers)):\n",
    "                y1, x1 = major_centers[i]\n",
    "                y2, x2 = major_centers[j]\n",
    "                \n",
    "                # Simple linear interpolation for road path\n",
    "                steps = max(abs(x2-x1), abs(y2-y1))\n",
    "                if steps > 0:\n",
    "                    for step in range(steps):\n",
    "                        x = int(x1 + (x2-x1) * step / steps)\n",
    "                        y = int(y1 + (y2-y1) * step / steps)\n",
    "                        \n",
    "                        # Add road with some width\n",
    "                        for dy in range(-2, 3):\n",
    "                            for dx in range(-2, 3):\n",
    "                                ny, nx = y + dy, x + dx\n",
    "                                if 0 <= ny < height and 0 <= nx < width:\n",
    "                                    roads[ny, nx] = min(roads[ny, nx], 0)\n",
    "    \n",
    "    # Calculate distance to roads\n",
    "    from scipy.ndimage import distance_transform_edt\n",
    "    road_mask = roads == 0\n",
    "    if np.any(road_mask):\n",
    "        roads = distance_transform_edt(~road_mask) * 30  # Convert to meters (30m resolution)\n",
    "    \n",
    "    # 9. Generate settlements (distance to urban areas)\n",
    "    print(\"Generating settlement proximity...\")\n",
    "    urban_mask = lulc == 2\n",
    "    if np.any(urban_mask):\n",
    "        settlements = distance_transform_edt(~urban_mask) * 30  # Convert to meters\n",
    "    else:\n",
    "        settlements = np.full((height, width), 5000.0)\n",
    "    \n",
    "    # 10. Generate fire labels with realistic patterns\n",
    "    print(\"Generating fire occurrence labels...\")\n",
    "    fire_labels = np.zeros((height, width))\n",
    "    \n",
    "    # Fire risk factors\n",
    "    fire_risk = np.zeros((height, width))\n",
    "    \n",
    "    # Temperature effect (higher temp = higher risk)\n",
    "    fire_risk += (temperature - 15) / 30 * 0.3\n",
    "    \n",
    "    # Humidity effect (lower humidity = higher risk)\n",
    "    fire_risk += (80 - humidity) / 70 * 0.2\n",
    "    \n",
    "    # Wind effect (higher wind = higher risk)\n",
    "    fire_risk += wind_speed / 25 * 0.1\n",
    "    \n",
    "    # Drought effect (low rainfall = higher risk)\n",
    "    fire_risk += (30 - rainfall) / 30 * 0.2\n",
    "    \n",
    "    # Vegetation effect (forest/shrub = higher risk)\n",
    "    veg_risk = np.zeros_like(lulc)\n",
    "    veg_risk[lulc == 5] = 0.1  # Forest\n",
    "    veg_risk[lulc == 6] = 0.15  # Shrubland\n",
    "    veg_risk[lulc == 4] = 0.05  # Grassland\n",
    "    fire_risk += veg_risk\n",
    "    \n",
    "    # Human activity effect (closer to roads/settlements = higher risk)\n",
    "    fire_risk += np.exp(-roads / 1000) * 0.05\n",
    "    fire_risk += np.exp(-settlements / 2000) * 0.03\n",
    "    \n",
    "    # Normalize fire risk\n",
    "    fire_risk = np.clip(fire_risk, 0, 1)\n",
    "    \n",
    "    # Generate fire events\n",
    "    for event in range(num_fire_events):\n",
    "        # Select fire starting point based on risk\n",
    "        risk_flat = fire_risk.flatten()\n",
    "        risk_prob = risk_flat / np.sum(risk_flat)\n",
    "        \n",
    "        start_idx = np.random.choice(len(risk_flat), p=risk_prob)\n",
    "        start_y, start_x = np.unravel_index(start_idx, (height, width))\n",
    "        \n",
    "        # Fire spread simulation (simple)\n",
    "        fire_size = np.random.uniform(50, 200)  # Fire radius\n",
    "        fire_intensity = np.random.uniform(0.3, 0.8)\n",
    "        \n",
    "        # Create fire spread pattern\n",
    "        fire_dist = np.sqrt((X - start_x)**2 + (Y - start_y)**2)\n",
    "        fire_spread = np.exp(-fire_dist / fire_size) * fire_intensity\n",
    "        \n",
    "        # Wind direction influence on fire spread\n",
    "        wind_influence = np.cos(np.radians(wind_dir[start_y, start_x] - \n",
    "                                         np.arctan2(Y - start_y, X - start_x) * 180 / np.pi))\n",
    "        fire_spread *= (1 + wind_influence * 0.3)\n",
    "        \n",
    "        # Apply fire spread to labels\n",
    "        fire_threshold = 0.1\n",
    "        fire_labels = np.maximum(fire_labels, (fire_spread > fire_threshold).astype(float))\n",
    "    \n",
    "    # Ensure fire labels are binary\n",
    "    fire_labels = (fire_labels > 0.5).astype(float)\n",
    "    \n",
    "    # Create final dataset dictionary\n",
    "    dataset = {\n",
    "        'temperature': temperature,\n",
    "        'humidity': humidity,\n",
    "        'wind_speed': wind_speed,\n",
    "        'wind_dir': wind_dir,\n",
    "        'rainfall': rainfall,\n",
    "        'dem': dem,\n",
    "        'lulc': lulc,\n",
    "        'roads': roads,\n",
    "        'settlements': settlements,\n",
    "        'fire_labels': fire_labels\n",
    "    }\n",
    "    \n",
    "    return dataset, profile\n",
    "\n",
    "# Generate the realistic dataset\n",
    "print(\"üî• Generating realistic forest fire dataset...\")\n",
    "realistic_data, data_profile = generate_realistic_dataset(\n",
    "    height=300, width=300, num_fire_events=20, seed=42\n",
    ")\n",
    "\n",
    "print(f\"Dataset generated with {realistic_data['fire_labels'].sum():.0f} fire pixels out of {realistic_data['fire_labels'].size} total pixels\")\n",
    "print(f\"Fire occurrence rate: {realistic_data['fire_labels'].mean()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38c2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the realistic dataset to GeoTIFF files\n",
    "print(\"üíæ Saving realistic dataset to GeoTIFF files...\")\n",
    "\n",
    "for name, data in realistic_data.items():\n",
    "    filepath = f'data/{name}.tif'\n",
    "    with rasterio.open(filepath, 'w', **data_profile) as dst:\n",
    "        dst.write(data.astype(np.float32), 1)\n",
    "    print(f\"‚úÖ Saved {name}.tif\")\n",
    "\n",
    "print(\"\\nüìä Dataset Statistics:\")\n",
    "print(\"=\" * 50)\n",
    "for name, data in realistic_data.items():\n",
    "    print(f\"{name:12s}: min={np.min(data):8.2f}, max={np.max(data):8.2f}, mean={np.mean(data):8.2f}, std={np.std(data):8.2f}\")\n",
    "\n",
    "# Visualize the generated dataset\n",
    "print(\"\\nüé® Visualizing generated dataset...\")\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
    "axes = axes.flatten()\n",
    "\n",
    "data_items = list(realistic_data.items())\n",
    "cmaps = ['Reds', 'Blues', 'Greens', 'plasma', 'viridis', 'terrain', 'tab10', 'copper', 'cool', 'RdYlBu_r']\n",
    "\n",
    "for i, (name, data) in enumerate(data_items):\n",
    "    if i < len(axes):\n",
    "        ax = axes[i]\n",
    "        im = ax.imshow(data, cmap=cmaps[i % len(cmaps)])\n",
    "        ax.set_title(f'{name.replace(\"_\", \" \").title()}')\n",
    "        ax.axis('off')\n",
    "        plt.colorbar(im, ax=ax, shrink=0.6)\n",
    "\n",
    "# Hide unused subplots\n",
    "for i in range(len(data_items), len(axes)):\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.suptitle('üî• Realistic Forest Fire Dataset', fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Realistic dataset generation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8504abe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_dataset_quality(data_dict):\n",
    "    \"\"\"\n",
    "    Analyze the quality and relationships in the generated dataset\n",
    "    \"\"\"\n",
    "    print(\"üîç DATASET QUALITY ANALYSIS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Convert to DataFrame for correlation analysis\n",
    "    data_flat = {}\n",
    "    for name, data in data_dict.items():\n",
    "        data_flat[name] = data.flatten()\n",
    "    \n",
    "    df = pd.DataFrame(data_flat)\n",
    "    \n",
    "    # 1. Correlation Analysis\n",
    "    print(\"\\nüìà Correlation Matrix:\")\n",
    "    correlation_matrix = df.corr()\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "                square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Fire Risk Analysis\n",
    "    print(\"\\nüî• Fire Risk Analysis:\")\n",
    "    fire_pixels = df[df['fire_labels'] == 1]\n",
    "    no_fire_pixels = df[df['fire_labels'] == 0]\n",
    "    \n",
    "    print(f\"Total pixels: {len(df):,}\")\n",
    "    print(f\"Fire pixels: {len(fire_pixels):,} ({len(fire_pixels)/len(df)*100:.2f}%)\")\n",
    "    print(f\"No-fire pixels: {len(no_fire_pixels):,} ({len(no_fire_pixels)/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    # Compare fire vs no-fire conditions\n",
    "    print(\"\\nüìä Fire vs No-Fire Conditions:\")\n",
    "    features_to_compare = ['temperature', 'humidity', 'wind_speed', 'rainfall']\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, feature in enumerate(features_to_compare):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        # Create histograms\n",
    "        ax.hist(no_fire_pixels[feature], bins=50, alpha=0.7, label='No Fire', color='blue', density=True)\n",
    "        ax.hist(fire_pixels[feature], bins=50, alpha=0.7, label='Fire', color='red', density=True)\n",
    "        \n",
    "        ax.set_xlabel(feature.replace('_', ' ').title())\n",
    "        ax.set_ylabel('Density')\n",
    "        ax.legend()\n",
    "        ax.set_title(f'{feature.replace(\"_\", \" \").title()} Distribution')\n",
    "        \n",
    "        # Add statistics\n",
    "        fire_mean = fire_pixels[feature].mean()\n",
    "        no_fire_mean = no_fire_pixels[feature].mean()\n",
    "        ax.axvline(fire_mean, color='red', linestyle='--', alpha=0.8, label=f'Fire Mean: {fire_mean:.2f}')\n",
    "        ax.axvline(no_fire_mean, color='blue', linestyle='--', alpha=0.8, label=f'No Fire Mean: {no_fire_mean:.2f}')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Spatial Analysis\n",
    "    print(\"\\nüó∫Ô∏è Spatial Fire Distribution:\")\n",
    "    fire_raster = data_dict['fire_labels']\n",
    "    \n",
    "    # Calculate fire density in different regions\n",
    "    h, w = fire_raster.shape\n",
    "    region_size = 50\n",
    "    \n",
    "    fire_density_map = np.zeros((h//region_size, w//region_size))\n",
    "    \n",
    "    for i in range(0, h, region_size):\n",
    "        for j in range(0, w, region_size):\n",
    "            region = fire_raster[i:i+region_size, j:j+region_size]\n",
    "            fire_density_map[i//region_size, j//region_size] = np.mean(region)\n",
    "    \n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(fire_density_map, cmap='Reds', interpolation='nearest')\n",
    "    plt.colorbar(label='Fire Density')\n",
    "    plt.title('Regional Fire Density Map')\n",
    "    plt.xlabel('Region X')\n",
    "    plt.ylabel('Region Y')\n",
    "    plt.show()\n",
    "    \n",
    "    # 4. Environmental Conditions Summary\n",
    "    print(\"\\nüå°Ô∏è Environmental Conditions Summary:\")\n",
    "    conditions_summary = pd.DataFrame({\n",
    "        'Feature': features_to_compare,\n",
    "        'Fire_Mean': [fire_pixels[f].mean() for f in features_to_compare],\n",
    "        'No_Fire_Mean': [no_fire_pixels[f].mean() for f in features_to_compare],\n",
    "        'Difference': [fire_pixels[f].mean() - no_fire_pixels[f].mean() for f in features_to_compare]\n",
    "    })\n",
    "    \n",
    "    print(conditions_summary.round(3))\n",
    "    \n",
    "    return correlation_matrix, conditions_summary\n",
    "\n",
    "# Run dataset quality analysis\n",
    "print(\"üî¨ Running dataset quality analysis...\")\n",
    "correlation_matrix, conditions_summary = analyze_dataset_quality(realistic_data)\n",
    "\n",
    "# Save analysis results\n",
    "correlation_matrix.to_csv('output/correlation_matrix.csv')\n",
    "conditions_summary.to_csv('output/fire_conditions_summary.csv', index=False)\n",
    "\n",
    "print(\"\\n‚úÖ Dataset quality analysis completed!\")\n",
    "print(\"üìÅ Analysis results saved to output/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2f02a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_custom_scenarios():\n",
    "    \"\"\"\n",
    "    Generate different fire scenarios for testing model robustness\n",
    "    \"\"\"\n",
    "    print(\"üé≠ GENERATING CUSTOM FIRE SCENARIOS\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    scenarios = {\n",
    "        'drought_scenario': {\n",
    "            'description': 'Severe drought conditions with low rainfall',\n",
    "            'params': {\n",
    "                'rainfall_factor': 0.3,\n",
    "                'temperature_boost': 5,\n",
    "                'humidity_drop': 15\n",
    "            }\n",
    "        },\n",
    "        'windy_scenario': {\n",
    "            'description': 'High wind conditions promoting fire spread',\n",
    "            'params': {\n",
    "                'wind_speed_factor': 2.0,\n",
    "                'wind_variability': 0.5\n",
    "            }\n",
    "        },\n",
    "        'summer_scenario': {\n",
    "            'description': 'Peak summer fire season conditions',\n",
    "            'params': {\n",
    "                'temperature_boost': 8,\n",
    "                'humidity_drop': 20,\n",
    "                'rainfall_factor': 0.2\n",
    "            }\n",
    "        },\n",
    "        'urban_interface': {\n",
    "            'description': 'Urban-wildland interface with high human activity',\n",
    "            'params': {\n",
    "                'urban_density': 3.0,\n",
    "                'road_density': 2.0,\n",
    "                'human_ignition_factor': 2.0\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    scenario_datasets = {}\n",
    "    \n",
    "    for scenario_name, scenario_info in scenarios.items():\n",
    "        print(f\"\\nüéØ Generating {scenario_name}: {scenario_info['description']}\")\n",
    "        \n",
    "        # Generate base dataset\n",
    "        base_data, profile = generate_realistic_dataset(\n",
    "            height=200, width=200, num_fire_events=10, seed=42\n",
    "        )\n",
    "        \n",
    "        # Apply scenario modifications\n",
    "        modified_data = base_data.copy()\n",
    "        params = scenario_info['params']\n",
    "        \n",
    "        # Temperature modifications\n",
    "        if 'temperature_boost' in params:\n",
    "            modified_data['temperature'] += params['temperature_boost']\n",
    "        \n",
    "        # Humidity modifications\n",
    "        if 'humidity_drop' in params:\n",
    "            modified_data['humidity'] -= params['humidity_drop']\n",
    "            modified_data['humidity'] = np.clip(modified_data['humidity'], 10, 95)\n",
    "        \n",
    "        # Rainfall modifications\n",
    "        if 'rainfall_factor' in params:\n",
    "            modified_data['rainfall'] *= params['rainfall_factor']\n",
    "        \n",
    "        # Wind modifications\n",
    "        if 'wind_speed_factor' in params:\n",
    "            modified_data['wind_speed'] *= params['wind_speed_factor']\n",
    "            modified_data['wind_speed'] = np.clip(modified_data['wind_speed'], 0, 40)\n",
    "        \n",
    "        # Urban/road density modifications\n",
    "        if 'urban_density' in params:\n",
    "            # Increase urban areas\n",
    "            urban_mask = modified_data['lulc'] == 2\n",
    "            urban_expanded = ndimage.binary_dilation(urban_mask, iterations=int(params['urban_density']))\n",
    "            modified_data['lulc'][urban_expanded] = 2\n",
    "        \n",
    "        if 'road_density' in params:\n",
    "            # Decrease road distances (more roads)\n",
    "            modified_data['roads'] /= params['road_density']\n",
    "        \n",
    "        # Recalculate fire risk for modified scenario\n",
    "        fire_risk = np.zeros_like(modified_data['temperature'])\n",
    "        \n",
    "        # Temperature effect\n",
    "        fire_risk += (modified_data['temperature'] - 15) / 30 * 0.3\n",
    "        \n",
    "        # Humidity effect\n",
    "        fire_risk += (80 - modified_data['humidity']) / 70 * 0.2\n",
    "        \n",
    "        # Wind effect\n",
    "        fire_risk += modified_data['wind_speed'] / 25 * 0.1\n",
    "        \n",
    "        # Drought effect\n",
    "        fire_risk += (30 - modified_data['rainfall']) / 30 * 0.2\n",
    "        \n",
    "        # Human activity effect\n",
    "        if 'human_ignition_factor' in params:\n",
    "            human_risk = np.exp(-modified_data['roads'] / 1000) * 0.05 * params['human_ignition_factor']\n",
    "            fire_risk += human_risk\n",
    "        \n",
    "        # Generate new fire labels based on modified risk\n",
    "        fire_labels = np.zeros_like(fire_risk)\n",
    "        fire_probability = np.clip(fire_risk, 0, 1)\n",
    "        \n",
    "        # Add some fire events based on probability\n",
    "        random_fire = np.random.random(fire_risk.shape)\n",
    "        fire_labels = (random_fire < fire_probability * 0.3).astype(float)\n",
    "        \n",
    "        # Ensure minimum fire coverage\n",
    "        if fire_labels.sum() < 100:\n",
    "            top_risk_indices = np.unravel_index(np.argsort(fire_risk.ravel())[-200:], fire_risk.shape)\n",
    "            fire_labels[top_risk_indices] = 1\n",
    "        \n",
    "        modified_data['fire_labels'] = fire_labels\n",
    "        scenario_datasets[scenario_name] = modified_data\n",
    "        \n",
    "        # Save scenario dataset\n",
    "        scenario_dir = f'data/scenarios/{scenario_name}'\n",
    "        os.makedirs(scenario_dir, exist_ok=True)\n",
    "        \n",
    "        for data_name, data_array in modified_data.items():\n",
    "            filepath = f'{scenario_dir}/{data_name}.tif'\n",
    "            with rasterio.open(filepath, 'w', **profile) as dst:\n",
    "                dst.write(data_array.astype(np.float32), 1)\n",
    "        \n",
    "        fire_count = modified_data['fire_labels'].sum()\n",
    "        fire_percentage = fire_count / modified_data['fire_labels'].size * 100\n",
    "        print(f\"   üí• Fire pixels: {fire_count:.0f} ({fire_percentage:.2f}%)\")\n",
    "    \n",
    "    return scenario_datasets\n",
    "\n",
    "# Generate custom scenarios\n",
    "print(\"üé≠ Creating custom fire scenarios...\")\n",
    "scenario_datasets = generate_custom_scenarios()\n",
    "\n",
    "# Visualize scenarios comparison\n",
    "print(\"\\nüìä Comparing fire scenarios...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot baseline first\n",
    "base_data = realistic_data['fire_labels']\n",
    "axes[0].imshow(base_data, cmap='Reds')\n",
    "axes[0].set_title(f'Baseline\\nFire Rate: {base_data.mean()*100:.1f}%')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Plot scenarios\n",
    "for i, (scenario_name, scenario_data) in enumerate(scenario_datasets.items(), 1):\n",
    "    if i < len(axes):\n",
    "        fire_data = scenario_data['fire_labels']\n",
    "        axes[i].imshow(fire_data, cmap='Reds')\n",
    "        axes[i].set_title(f'{scenario_name.replace(\"_\", \" \").title()}\\nFire Rate: {fire_data.mean()*100:.1f}%')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "# Hide unused subplot\n",
    "if len(scenario_datasets) + 1 < len(axes):\n",
    "    axes[-1].axis('off')\n",
    "\n",
    "plt.suptitle('üî• Fire Scenario Comparison', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Custom scenarios generated successfully!\")\n",
    "print(\"üìÅ Scenario datasets saved in data/scenarios/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c61ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_and_stack_features():\n",
    "    \"\"\"Load all raster files and stack them into feature array\"\"\"\n",
    "    \n",
    "    print(\"Loading and preprocessing raster data...\")\n",
    "    \n",
    "    features = {}\n",
    "    common_shape = None\n",
    "    common_transform = None\n",
    "    common_profile = None\n",
    "    \n",
    "    for name, filepath in processor.raster_files.items():\n",
    "        data, transform, crs, profile = processor.load_raster(filepath)\n",
    "        \n",
    "        if data is not None:\n",
    "            if common_shape is None:\n",
    "                common_shape = data.shape\n",
    "                common_transform = transform\n",
    "                common_profile = profile\n",
    "            \n",
    "            resampled_data, _, _ = processor.resample_raster(\n",
    "                data, transform, profile, processor.target_resolution\n",
    "            )\n",
    "            \n",
    "            if resampled_data.shape != common_shape:\n",
    "                resampled_data = np.resize(resampled_data, common_shape)\n",
    "            \n",
    "            features[name] = resampled_data\n",
    "            print(f\"Loaded {name}: {resampled_data.shape}\")\n",
    "    \n",
    "    dem = features['dem']\n",
    "    slope, aspect = processor.calculate_slope_aspect(dem)\n",
    "    features['slope'] = slope\n",
    "    features['aspect'] = aspect\n",
    "    \n",
    "    print(\"Visualizing key features...\")\n",
    "    processor.visualize_raster(features['temperature'], 'Temperature (¬∞C)', 'Reds')\n",
    "    processor.visualize_raster(features['fire_labels'], 'Fire Labels', 'RdYlBu_r')\n",
    "    processor.visualize_raster(features['slope'], 'Slope', 'terrain')\n",
    "    \n",
    "    feature_names = [name for name in features.keys() if name != 'fire_labels']\n",
    "    feature_stack = np.stack([features[name] for name in feature_names], axis=-1)\n",
    "    \n",
    "    labels = features['fire_labels']\n",
    "    \n",
    "    print(f\"Feature stack shape: {feature_stack.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Feature names: {feature_names}\")\n",
    "    \n",
    "    return feature_stack, labels, feature_names, common_transform, common_profile\n",
    "\n",
    "feature_stack, labels, feature_names, transform, profile = preprocess_and_stack_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881effff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FirePredictionModel:\n",
    "    def __init__(self, model_path=None):\n",
    "        self.model = None\n",
    "        self.feature_names = None\n",
    "        self.model_path = model_path or MODEL_PATH\n",
    "        \n",
    "    def prepare_data(self, feature_stack, labels):\n",
    "        \"\"\"Prepare data for training\"\"\"\n",
    "        height, width, n_features = feature_stack.shape\n",
    "        \n",
    "        X = feature_stack.reshape(-1, n_features)\n",
    "        y = labels.reshape(-1)\n",
    "        \n",
    "        valid_mask = ~np.isnan(X).any(axis=1) & ~np.isnan(y)\n",
    "        X = X[valid_mask]\n",
    "        y = y[valid_mask]\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def train_model(self, X, y):\n",
    "        \"\"\"Train RandomForest model\"\"\"\n",
    "        print(\"üîÑ Training RandomForest model...\")\n",
    "        print(f\"   Training samples: {len(X):,}\")\n",
    "        print(f\"   Features: {X.shape[1]}\")\n",
    "        \n",
    "        self.model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=15,\n",
    "            min_samples_split=5,\n",
    "            min_samples_leaf=2,\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        \n",
    "        self.model.fit(X, y)\n",
    "        \n",
    "        joblib.dump(self.model, self.model_path)\n",
    "        print(f\"‚úÖ Model trained and saved to {self.model_path}\")\n",
    "        \n",
    "    def load_model(self):\n",
    "        \"\"\"Load pre-trained model\"\"\"\n",
    "        if os.path.exists(self.model_path):\n",
    "            self.model = joblib.load(self.model_path)\n",
    "            print(f\"‚úÖ Model loaded from {self.model_path}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå No model found at {self.model_path}\")\n",
    "            return False\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained or loaded\")\n",
    "        \n",
    "        return self.model.predict(X)\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \"\"\"Get prediction probabilities\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained or loaded\")\n",
    "        \n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def get_feature_importance(self):\n",
    "        \"\"\"Get feature importance\"\"\"\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not trained or loaded\")\n",
    "        \n",
    "        return self.model.feature_importances_\n",
    "\n",
    "fire_model = FirePredictionModel()\n",
    "print(\"FirePredictionModel created successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec50219",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = fire_model.prepare_data(feature_stack, labels)\n",
    "print(f\"üìä Training data prepared: X={X.shape}, y={y.shape}\")\n",
    "\n",
    "# Simple model training logic based on user choice\n",
    "print(\"\\nü§ñ MODEL TRAINING/LOADING:\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "if RETRAIN_MODEL:\n",
    "    print(\"üîÑ Training new model as requested...\")\n",
    "    fire_model.train_model(X, y)\n",
    "else:\n",
    "    print(\"üìÇ Attempting to load existing model...\")\n",
    "    if fire_model.load_model():\n",
    "        print(\"‚úÖ Existing model loaded successfully!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  No existing model found - training new model...\")\n",
    "        fire_model.train_model(X, y)\n",
    "\n",
    "print(\"\\nüîÆ Making predictions...\")\n",
    "predictions = fire_model.predict(X)\n",
    "probabilities = fire_model.predict_proba(X)\n",
    "\n",
    "height, width = labels.shape\n",
    "prediction_map = np.full((height * width,), np.nan)\n",
    "\n",
    "valid_mask = ~np.isnan(feature_stack.reshape(-1, feature_stack.shape[-1])).any(axis=1) & ~np.isnan(labels.reshape(-1))\n",
    "prediction_map[valid_mask] = predictions\n",
    "\n",
    "prediction_map = prediction_map.reshape(height, width)\n",
    "\n",
    "fire_probability_map = np.full((height * width,), np.nan)\n",
    "fire_probability_map[valid_mask] = probabilities.ravel()\n",
    "fire_probability_map = fire_probability_map.reshape(height, width)\n",
    "\n",
    "print(\"Visualizing predictions...\")\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(labels, cmap='RdYlBu_r')\n",
    "plt.title('Actual Fire Labels')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(prediction_map, cmap='RdYlBu_r')\n",
    "plt.title('Predicted Fire Risk')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(fire_probability_map, cmap='Reds')\n",
    "plt.title('Fire Probability')\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Saving prediction maps...\")\n",
    "with rasterio.open('output/fire_prediction.tif', 'w', **profile) as dst:\n",
    "    dst.write(prediction_map.astype(np.float32), 1)\n",
    "\n",
    "with rasterio.open('output/fire_probability.tif', 'w', **profile) as dst:\n",
    "    dst.write(fire_probability_map.astype(np.float32), 1)\n",
    "\n",
    "print(\"Prediction maps saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf0f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FireSpreadSimulator:\n",
    "    def __init__(self, fire_probability_map, wind_speed, wind_dir, fuel_load, slope):\n",
    "        self.fire_prob = fire_probability_map\n",
    "        self.wind_speed = wind_speed\n",
    "        self.wind_dir = wind_dir\n",
    "        self.fuel_load = fuel_load\n",
    "        self.slope = slope\n",
    "        self.height, self.width = fire_probability_map.shape\n",
    "        \n",
    "        self.fire_state = np.zeros_like(fire_probability_map)\n",
    "        self.burned_state = np.zeros_like(fire_probability_map)\n",
    "        \n",
    "        high_risk_threshold = 0.7\n",
    "        self.fire_state[fire_probability_map > high_risk_threshold] = 1\n",
    "        \n",
    "    def calculate_spread_probability(self, i, j):\n",
    "        \"\"\"Calculate fire spread probability based on environmental factors\"\"\"\n",
    "        base_prob = 0.3\n",
    "        \n",
    "        wind_factor = min(self.wind_speed[i, j] / 20.0, 1.0)\n",
    "        fuel_factor = min(self.fuel_load[i, j] / 10.0, 1.0)\n",
    "        slope_factor = min(self.slope[i, j] / 45.0, 1.0) * 0.5\n",
    "        \n",
    "        spread_prob = base_prob + (wind_factor * 0.4) + (fuel_factor * 0.2) + (slope_factor * 0.1)\n",
    "        \n",
    "        return min(spread_prob, 1.0)\n",
    "    \n",
    "    def get_neighbors(self, i, j):\n",
    "        \"\"\"Get valid neighboring cells\"\"\"\n",
    "        neighbors = []\n",
    "        for di in [-1, 0, 1]:\n",
    "            for dj in [-1, 0, 1]:\n",
    "                if di == 0 and dj == 0:\n",
    "                    continue\n",
    "                ni, nj = i + di, j + dj\n",
    "                if 0 <= ni < self.height and 0 <= nj < self.width:\n",
    "                    neighbors.append((ni, nj))\n",
    "        return neighbors\n",
    "    \n",
    "    def simulate_step(self):\n",
    "        \"\"\"Simulate one time step of fire spread\"\"\"\n",
    "        new_fire_state = self.fire_state.copy()\n",
    "        \n",
    "        fire_cells = np.where(self.fire_state == 1)\n",
    "        \n",
    "        for i, j in zip(fire_cells[0], fire_cells[1]):\n",
    "            if self.burned_state[i, j] == 1:\n",
    "                continue\n",
    "            \n",
    "            spread_prob = self.calculate_spread_probability(i, j)\n",
    "            \n",
    "            for ni, nj in self.get_neighbors(i, j):\n",
    "                if (self.fire_state[ni, nj] == 0 and \n",
    "                    self.burned_state[ni, nj] == 0 and\n",
    "                    np.random.random() < spread_prob):\n",
    "                    new_fire_state[ni, nj] = 1\n",
    "            \n",
    "            self.burned_state[i, j] = 1\n",
    "            new_fire_state[i, j] = 0\n",
    "        \n",
    "        self.fire_state = new_fire_state\n",
    "        \n",
    "        return self.fire_state + self.burned_state * 0.5\n",
    "    \n",
    "    def simulate_spread(self, hours):\n",
    "        \"\"\"Simulate fire spread for given number of hours\"\"\"\n",
    "        spread_maps = {}\n",
    "        \n",
    "        for hour in [1, 2, 3, 6, 12]:\n",
    "            if hour > hours:\n",
    "                break\n",
    "            \n",
    "            current_state = self.fire_state.copy()\n",
    "            current_burned = self.burned_state.copy()\n",
    "            \n",
    "            for step in range(hour * 6):\n",
    "                self.simulate_step()\n",
    "            \n",
    "            spread_maps[f'{hour}h'] = self.fire_state + self.burned_state * 0.5\n",
    "            \n",
    "            self.fire_state = current_state\n",
    "            self.burned_state = current_burned\n",
    "        \n",
    "        return spread_maps\n",
    "\n",
    "simulator = FireSpreadSimulator(\n",
    "    fire_probability_map,\n",
    "    feature_stack[:, :, feature_names.index('wind_speed')],\n",
    "    feature_stack[:, :, feature_names.index('wind_dir')],\n",
    "    feature_stack[:, :, feature_names.index('lulc')],\n",
    "    feature_stack[:, :, feature_names.index('slope')]\n",
    ")\n",
    "\n",
    "print(\"Simulating fire spread...\")\n",
    "spread_maps = simulator.simulate_spread(12)\n",
    "\n",
    "print(\"Visualizing fire spread simulation...\")\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "axes[0].imshow(fire_probability_map, cmap='Reds')\n",
    "axes[0].set_title('Initial Fire Probability')\n",
    "axes[0].axis('off')\n",
    "\n",
    "for idx, (time_label, spread_map) in enumerate(spread_maps.items(), 1):\n",
    "    axes[idx].imshow(spread_map, cmap='RdYlBu_r')\n",
    "    axes[idx].set_title(f'Fire Spread - {time_label}')\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Saving fire spread maps...\")\n",
    "for time_label, spread_map in spread_maps.items():\n",
    "    output_path = f'output/fire_spread_{time_label}.tif'\n",
    "    with rasterio.open(output_path, 'w', **profile) as dst:\n",
    "        dst.write(spread_map.astype(np.float32), 1)\n",
    "\n",
    "print(\"Fire spread simulation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492228b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(y_true, y_pred):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "    \n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='binary')\n",
    "    recall = recall_score(y_true, y_pred, average='binary')\n",
    "    f1 = f1_score(y_true, y_pred, average='binary')\n",
    "    \n",
    "    print(\"Model Evaluation Results:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall:    {recall:.4f}\")\n",
    "    print(f\"F1-Score:  {f1:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred, target_names=['No Fire', 'Fire'], labels=[0, 1]))\n",
    "    \n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score'],\n",
    "        'Value': [accuracy, precision, recall, f1]\n",
    "    })\n",
    "    \n",
    "    metrics_df.to_csv('output/model_report.csv', index=False)\n",
    "    print(\"\\nMetrics saved to output/model_report.csv\")\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "def plot_feature_importance(model, feature_names):\n",
    "    \"\"\"Plot feature importance from the trained model\"\"\"\n",
    "    \n",
    "    importance = model.get_feature_importance()\n",
    "    \n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importance\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=feature_importance_df, x='Importance', y='Feature')\n",
    "    plt.title('Feature Importance for Fire Prediction')\n",
    "    plt.xlabel('Importance Score')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return feature_importance_df\n",
    "\n",
    "print(\"Evaluating model performance...\")\n",
    "metrics_df = evaluate_model(y, predictions.astype(int))\n",
    "\n",
    "print(\"\\nAnalyzing feature importance...\")\n",
    "feature_importance_df = plot_feature_importance(fire_model, feature_names)\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features:\")\n",
    "print(feature_importance_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255af45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RasterUtils:\n",
    "    @staticmethod\n",
    "    def raster_to_array(filepath):\n",
    "        \"\"\"Convert raster file to numpy array\"\"\"\n",
    "        with rasterio.open(filepath) as src:\n",
    "            array = src.read(1)\n",
    "            transform = src.transform\n",
    "            crs = src.crs\n",
    "        return array, transform, crs\n",
    "    \n",
    "    @staticmethod\n",
    "    def array_to_raster(array, filepath, transform, crs, dtype=np.float32):\n",
    "        \"\"\"Save numpy array as raster file\"\"\"\n",
    "        profile = {\n",
    "            'driver': 'GTiff',\n",
    "            'height': array.shape[0],\n",
    "            'width': array.shape[1],\n",
    "            'count': 1,\n",
    "            'dtype': dtype,\n",
    "            'crs': crs,\n",
    "            'transform': transform,\n",
    "            'compress': 'lzw'\n",
    "        }\n",
    "        \n",
    "        with rasterio.open(filepath, 'w', **profile) as dst:\n",
    "            dst.write(array.astype(dtype), 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def visualize_comparison(data_dict, titles=None, cmap='viridis', figsize=(15, 10)):\n",
    "        \"\"\"Visualize multiple rasters for comparison\"\"\"\n",
    "        n_plots = len(data_dict)\n",
    "        cols = min(3, n_plots)\n",
    "        rows = (n_plots + cols - 1) // cols\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
    "        if rows == 1:\n",
    "            axes = [axes] if n_plots == 1 else axes\n",
    "        else:\n",
    "            axes = axes.flatten()\n",
    "        \n",
    "        for idx, (key, data) in enumerate(data_dict.items()):\n",
    "            ax = axes[idx] if n_plots > 1 else axes\n",
    "            im = ax.imshow(data, cmap=cmap)\n",
    "            ax.set_title(titles[idx] if titles else key)\n",
    "            ax.axis('off')\n",
    "            plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "        \n",
    "        for idx in range(n_plots, len(axes)):\n",
    "            axes[idx].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    @staticmethod\n",
    "    def calculate_statistics(array, name=\"Array\"):\n",
    "        \"\"\"Calculate and display array statistics\"\"\"\n",
    "        stats = {\n",
    "            'Mean': np.nanmean(array),\n",
    "            'Std': np.nanstd(array),\n",
    "            'Min': np.nanmin(array),\n",
    "            'Max': np.nanmax(array),\n",
    "            'Median': np.nanmedian(array),\n",
    "            'Non-null count': np.sum(~np.isnan(array))\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nStatistics for {name}:\")\n",
    "        print(\"-\" * 30)\n",
    "        for key, value in stats.items():\n",
    "            print(f\"{key}: {value:.4f}\")\n",
    "        \n",
    "        return stats\n",
    "\n",
    "utils = RasterUtils()\n",
    "\n",
    "print(\"Calculating statistics for key outputs...\")\n",
    "utils.calculate_statistics(prediction_map, \"Fire Prediction Map\")\n",
    "utils.calculate_statistics(fire_probability_map, \"Fire Probability Map\")\n",
    "\n",
    "print(\"\\nVisualizing model outputs...\")\n",
    "visualization_data = {\n",
    "    'Fire Labels': labels,\n",
    "    'Fire Prediction': prediction_map,\n",
    "    'Fire Probability': fire_probability_map\n",
    "}\n",
    "\n",
    "utils.visualize_comparison(\n",
    "    visualization_data,\n",
    "    cmap='RdYlBu_r',\n",
    "    figsize=(15, 5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afca84df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fire_spread_animation(spread_maps, output_path='output/fire_spread_animation.gif'):\n",
    "    \"\"\"Create animated GIF of fire spread simulation\"\"\"\n",
    "    \n",
    "    time_steps = ['1h', '2h', '3h', '6h', '12h']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    def animate(frame):\n",
    "        ax.clear()\n",
    "        time_step = time_steps[frame]\n",
    "        \n",
    "        if time_step in spread_maps:\n",
    "            im = ax.imshow(spread_maps[time_step], cmap='RdYlBu_r', vmin=0, vmax=1)\n",
    "            ax.set_title(f'Fire Spread Simulation - {time_step}', fontsize=14)\n",
    "            ax.axis('off')\n",
    "            \n",
    "            if frame == 0:\n",
    "                plt.colorbar(im, ax=ax, shrink=0.8)\n",
    "        \n",
    "        return []\n",
    "    \n",
    "    anim = animation.FuncAnimation(\n",
    "        fig, animate, frames=len(time_steps), \n",
    "        interval=1000, blit=False, repeat=True\n",
    "    )\n",
    "    \n",
    "    try:\n",
    "        anim.save(output_path, writer='pillow', fps=1)\n",
    "        print(f\"Animation saved to {output_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Could not save animation: {e}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return anim\n",
    "\n",
    "def create_comprehensive_visualization():\n",
    "    \"\"\"Create comprehensive visualization of all results\"\"\"\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 15))\n",
    "    \n",
    "    gs = fig.add_gridspec(3, 4, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    ax1.imshow(labels, cmap='RdYlBu_r')\n",
    "    ax1.set_title('Fire Labels (Ground Truth)')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    ax2.imshow(prediction_map, cmap='RdYlBu_r')\n",
    "    ax2.set_title('Fire Prediction')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.imshow(fire_probability_map, cmap='Reds')\n",
    "    ax3.set_title('Fire Probability')\n",
    "    ax3.axis('off')\n",
    "    \n",
    "    ax4 = fig.add_subplot(gs[0, 3])\n",
    "    ax4.imshow(feature_stack[:, :, feature_names.index('temperature')], cmap='Reds')\n",
    "    ax4.set_title('Temperature')\n",
    "    ax4.axis('off')\n",
    "    \n",
    "    spread_axes = [\n",
    "        fig.add_subplot(gs[1, 0]),\n",
    "        fig.add_subplot(gs[1, 1]),\n",
    "        fig.add_subplot(gs[1, 2]),\n",
    "        fig.add_subplot(gs[1, 3])\n",
    "    ]\n",
    "    \n",
    "    spread_times = ['1h', '2h', '3h', '6h']\n",
    "    for ax, time_step in zip(spread_axes, spread_times):\n",
    "        if time_step in spread_maps:\n",
    "            ax.imshow(spread_maps[time_step], cmap='RdYlBu_r')\n",
    "            ax.set_title(f'Fire Spread - {time_step}')\n",
    "        ax.axis('off')\n",
    "    \n",
    "    ax_12h = fig.add_subplot(gs[2, :2])\n",
    "    if '12h' in spread_maps:\n",
    "        ax_12h.imshow(spread_maps['12h'], cmap='RdYlBu_r')\n",
    "        ax_12h.set_title('Fire Spread - 12h')\n",
    "    ax_12h.axis('off')\n",
    "    \n",
    "    ax_metrics = fig.add_subplot(gs[2, 2:])\n",
    "    metrics_df.plot(x='Metric', y='Value', kind='bar', ax=ax_metrics)\n",
    "    ax_metrics.set_title('Model Performance Metrics')\n",
    "    ax_metrics.set_ylabel('Score')\n",
    "    ax_metrics.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.suptitle('Forest Fire Risk Prediction & Spread Simulation Results', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('output/comprehensive_results.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Creating comprehensive visualization...\")\n",
    "create_comprehensive_visualization()\n",
    "\n",
    "print(\"Creating fire spread animation...\")\n",
    "animation_obj = create_fire_spread_animation(spread_maps)\n",
    "\n",
    "print(\"All visualizations completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee06be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_complete_pipeline():\n",
    "    \"\"\"Execute the complete forest fire prediction and simulation pipeline\"\"\"\n",
    "    \n",
    "    print(\"üî• FOREST FIRE RISK PREDICTION & SPREAD SIMULATION PIPELINE üî•\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    pipeline_steps = [\n",
    "        \"1. Data Preprocessing\",\n",
    "        \"2. Model Training/Loading\",\n",
    "        \"3. Fire Risk Prediction\",\n",
    "        \"4. Fire Spread Simulation\",\n",
    "        \"5. Model Evaluation\",\n",
    "        \"6. Output Generation\"\n",
    "    ]\n",
    "    \n",
    "    for step in pipeline_steps:\n",
    "        print(f\"‚úÖ {step}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PIPELINE EXECUTION SUMMARY\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(f\"üìä Model Training: {'NEW MODEL TRAINED' if RETRAIN_MODEL else 'EXISTING MODEL LOADED'}\")\n",
    "    print(f\"üìà Model Performance:\")\n",
    "    print(f\"   - Accuracy: {metrics_df[metrics_df['Metric'] == 'Accuracy']['Value'].iloc[0]:.4f}\")\n",
    "    print(f\"   - F1-Score: {metrics_df[metrics_df['Metric'] == 'F1-Score']['Value'].iloc[0]:.4f}\")\n",
    "    \n",
    "    print(f\"üî• Fire Spread Simulation: {len(spread_maps)} time steps\")\n",
    "    print(f\"üìÅ Output Files Generated:\")\n",
    "    \n",
    "    output_files = [\n",
    "        'fire_prediction.tif',\n",
    "        'fire_probability.tif',\n",
    "        'fire_spread_1h.tif',\n",
    "        'fire_spread_2h.tif',\n",
    "        'fire_spread_3h.tif',\n",
    "        'fire_spread_6h.tif',\n",
    "        'fire_spread_12h.tif',\n",
    "        'model_report.csv',\n",
    "        'comprehensive_results.png',\n",
    "        'fire_spread_animation.gif'\n",
    "    ]\n",
    "    \n",
    "    for file in output_files:\n",
    "        filepath = f'output/{file}'\n",
    "        if os.path.exists(filepath):\n",
    "            print(f\"   ‚úÖ {file}\")\n",
    "        else:\n",
    "            print(f\"   ‚ùå {file} (not created)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    return {\n",
    "        'prediction_map': prediction_map,\n",
    "        'probability_map': fire_probability_map,\n",
    "        'spread_maps': spread_maps,\n",
    "        'metrics': metrics_df,\n",
    "        'feature_importance': feature_importance_df\n",
    "    }\n",
    "\n",
    "print(\"Running complete pipeline...\")\n",
    "pipeline_results = run_complete_pipeline()\n",
    "\n",
    "print(\"\\nüéØ USAGE INSTRUCTIONS:\")\n",
    "print(\"-\" * 50)\n",
    "print(\"üìù Model Training Control:\")\n",
    "print(\"   ‚Ä¢ Set RETRAIN_MODEL = True to train a new model\")\n",
    "print(\"   ‚Ä¢ Set RETRAIN_MODEL = False to use existing model\")\n",
    "print(\"   ‚Ä¢ Set FORCE_RETRAIN = True to force training (ignores existing model)\")\n",
    "print()\n",
    "print(\"üóÇÔ∏è  Data Management:\")\n",
    "print(\"   ‚Ä¢ Replace sample data with your actual GeoTIFF files in 'data/' folder\")\n",
    "print(\"   ‚Ä¢ Ensure all GeoTIFF files have the same spatial extent and projection\")\n",
    "print()\n",
    "print(\"‚öôÔ∏è  Customization:\")\n",
    "print(\"   ‚Ä¢ Adjust model parameters in FirePredictionModel class\")\n",
    "print(\"   ‚Ä¢ Modify spread simulation parameters in FireSpreadSimulator class\")\n",
    "print(\"   ‚Ä¢ Change MODEL_PATH to use different model file location\")\n",
    "print()\n",
    "print(\"üìÅ Output Files:\")\n",
    "print(\"   ‚Ä¢ All prediction outputs saved in 'output/' directory\")\n",
    "print(\"   ‚Ä¢ Trained model saved in 'models/' directory for reuse\")\n",
    "print(\"   ‚Ä¢ Scenario data saved in 'data/scenarios/' directory\")\n",
    "\n",
    "print(\"\\nüöÄ READY FOR DEPLOYMENT!\")\n",
    "print(\"The pipeline is fully functional and ready for real-world forest fire prediction!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57caa02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comprehensive_summary():\n",
    "    \"\"\"\n",
    "    Create a comprehensive summary of all important outputs from the forest fire prediction system\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üî•\" * 50)\n",
    "    print(\"üéØ COMPREHENSIVE FOREST FIRE PREDICTION SUMMARY üéØ\")\n",
    "    print(\"üî•\" * 50)\n",
    "    print()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 1. SYSTEM CONFIGURATION\n",
    "    # ============================================================================\n",
    "    print(\"‚öôÔ∏è  SYSTEM CONFIGURATION\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"üìä Model Training Mode: {'NEW MODEL TRAINED' if RETRAIN_MODEL else 'EXISTING MODEL LOADED'}\")\n",
    "    print(f\"üìÅ Model Path: {MODEL_PATH}\")\n",
    "    print(f\"üóÇÔ∏è  Data Dimensions: {height}x{width} pixels\")\n",
    "    print(f\"üìà Total Features: {len(feature_names)}\")\n",
    "    print(f\"üéØ Feature List: {', '.join(feature_names)}\")\n",
    "    print()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 2. DATASET STATISTICS\n",
    "    # ============================================================================\n",
    "    print(\"üìä DATASET STATISTICS\")\n",
    "    print(\"=\" * 40)\n",
    "    total_pixels = realistic_data['fire_labels'].size\n",
    "    fire_pixels = realistic_data['fire_labels'].sum()\n",
    "    fire_rate = fire_pixels / total_pixels * 100\n",
    "    \n",
    "    print(f\"üåç Total Pixels: {total_pixels:,}\")\n",
    "    print(f\"üî• Fire Pixels: {fire_pixels:.0f}\")\n",
    "    print(f\"üìà Fire Occurrence Rate: {fire_rate:.2f}%\")\n",
    "    print(f\"üå°Ô∏è  Temperature Range: {np.min(realistic_data['temperature']):.1f}¬∞C to {np.max(realistic_data['temperature']):.1f}¬∞C\")\n",
    "    print(f\"üíß Humidity Range: {np.min(realistic_data['humidity']):.1f}% to {np.max(realistic_data['humidity']):.1f}%\")\n",
    "    print(f\"üí® Wind Speed Range: {np.min(realistic_data['wind_speed']):.1f} to {np.max(realistic_data['wind_speed']):.1f} m/s\")\n",
    "    print(f\"üåßÔ∏è  Rainfall Range: {np.min(realistic_data['rainfall']):.1f} to {np.max(realistic_data['rainfall']):.1f} mm\")\n",
    "    print()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 3. MODEL PERFORMANCE METRICS\n",
    "    # ============================================================================\n",
    "    print(\"üéØ MODEL PERFORMANCE METRICS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Display metrics in a formatted table\n",
    "    print(f\"{'Metric':<12} {'Value':<10} {'Interpretation'}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for _, row in metrics_df.iterrows():\n",
    "        metric = row['Metric']\n",
    "        value = row['Value']\n",
    "        \n",
    "        # Add interpretation\n",
    "        if metric == 'Accuracy':\n",
    "            interpretation = \"Overall correctness\"\n",
    "        elif metric == 'Precision':\n",
    "            interpretation = \"Fire prediction accuracy\"\n",
    "        elif metric == 'Recall':\n",
    "            interpretation = \"Fire detection completeness\"\n",
    "        elif metric == 'F1-Score':\n",
    "            interpretation = \"Balanced performance\"\n",
    "        else:\n",
    "            interpretation = \"Model performance\"\n",
    "            \n",
    "        print(f\"{metric:<12} {value:<10.4f} {interpretation}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # Performance evaluation\n",
    "    accuracy = metrics_df[metrics_df['Metric'] == 'Accuracy']['Value'].iloc[0]\n",
    "    f1_score = metrics_df[metrics_df['Metric'] == 'F1-Score']['Value'].iloc[0]\n",
    "    \n",
    "    if accuracy > 0.85 and f1_score > 0.8:\n",
    "        performance_rating = \"üåü EXCELLENT\"\n",
    "    elif accuracy > 0.75 and f1_score > 0.7:\n",
    "        performance_rating = \"‚úÖ GOOD\"\n",
    "    elif accuracy > 0.65 and f1_score > 0.6:\n",
    "        performance_rating = \"‚ö†Ô∏è  FAIR\"\n",
    "    else:\n",
    "        performance_rating = \"‚ùå NEEDS IMPROVEMENT\"\n",
    "    \n",
    "    print(f\"üìä Overall Model Performance: {performance_rating}\")\n",
    "    print()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 4. FEATURE IMPORTANCE ANALYSIS\n",
    "    # ============================================================================\n",
    "    print(\"üîç FEATURE IMPORTANCE ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Top 5 Most Important Features for Fire Prediction:\")\n",
    "    print()\n",
    "    \n",
    "    for i, (_, row) in enumerate(feature_importance_df.head().iterrows(), 1):\n",
    "        importance = row['Importance']\n",
    "        feature = row['Feature']\n",
    "        \n",
    "        # Create visual bar\n",
    "        bar_length = int(importance * 50)  # Scale to 50 characters\n",
    "        bar = \"‚ñà\" * bar_length + \"‚ñë\" * (50 - bar_length)\n",
    "        \n",
    "        print(f\"{i}. {feature:<15} {bar} {importance:.3f}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 5. FIRE SPREAD SIMULATION RESULTS\n",
    "    # ============================================================================\n",
    "    print(\"üî• FIRE SPREAD SIMULATION RESULTS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Fire spread simulation completed for multiple time horizons:\")\n",
    "    print()\n",
    "    \n",
    "    for time_step, spread_data in spread_maps.items():\n",
    "        affected_pixels = np.sum(spread_data > 0)\n",
    "        affected_percentage = (affected_pixels / spread_data.size) * 100\n",
    "        print(f\"‚è∞ {time_step:<4} | Affected Area: {affected_pixels:>6,} pixels ({affected_percentage:>5.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 6. SCENARIO ANALYSIS\n",
    "    # ============================================================================\n",
    "    print(\"üé≠ SCENARIO ANALYSIS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"Generated custom fire scenarios:\")\n",
    "    print()\n",
    "    \n",
    "    scenarios_info = {\n",
    "        'drought_scenario': 'Severe drought conditions',\n",
    "        'windy_scenario': 'High wind conditions',\n",
    "        'summer_scenario': 'Peak summer fire season',\n",
    "        'urban_interface': 'Urban-wildland interface'\n",
    "    }\n",
    "    \n",
    "    for scenario_name, description in scenarios_info.items():\n",
    "        if scenario_name in scenario_datasets:\n",
    "            scenario_fire_rate = scenario_datasets[scenario_name]['fire_labels'].mean() * 100\n",
    "            print(f\"üéØ {scenario_name.replace('_', ' ').title():<20} | Fire Rate: {scenario_fire_rate:>5.1f}% | {description}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 7. OUTPUT FILES SUMMARY\n",
    "    # ============================================================================\n",
    "    print(\"üìÅ OUTPUT FILES SUMMARY\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    output_files = [\n",
    "        ('fire_prediction.tif', 'Fire risk prediction map'),\n",
    "        ('fire_probability.tif', 'Fire probability map'),\n",
    "        ('fire_spread_1h.tif', 'Fire spread after 1 hour'),\n",
    "        ('fire_spread_2h.tif', 'Fire spread after 2 hours'),\n",
    "        ('fire_spread_3h.tif', 'Fire spread after 3 hours'),\n",
    "        ('fire_spread_6h.tif', 'Fire spread after 6 hours'),\n",
    "        ('fire_spread_12h.tif', 'Fire spread after 12 hours'),\n",
    "        ('model_report.csv', 'Model performance metrics'),\n",
    "        ('correlation_matrix.csv', 'Feature correlation analysis'),\n",
    "        ('fire_conditions_summary.csv', 'Fire vs no-fire conditions'),\n",
    "        ('comprehensive_results.png', 'Complete visualization summary'),\n",
    "        ('fire_spread_animation.gif', 'Animated fire spread simulation')\n",
    "    ]\n",
    "    \n",
    "    print(\"Generated Files:\")\n",
    "    for filename, description in output_files:\n",
    "        filepath = f'output/{filename}'\n",
    "        status = \"‚úÖ\" if os.path.exists(filepath) else \"‚ùå\"\n",
    "        file_size = \"\"\n",
    "        if os.path.exists(filepath):\n",
    "            size_kb = os.path.getsize(filepath) / 1024\n",
    "            file_size = f\"({size_kb:.1f} KB)\"\n",
    "        \n",
    "        print(f\"{status} {filename:<30} {file_size:<12} {description}\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 8. KEY INSIGHTS AND RECOMMENDATIONS\n",
    "    # ============================================================================\n",
    "    print(\"üí° KEY INSIGHTS AND RECOMMENDATIONS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Analyze feature importance for insights\n",
    "    top_feature = feature_importance_df.iloc[0]['Feature']\n",
    "    top_importance = feature_importance_df.iloc[0]['Importance']\n",
    "    \n",
    "    print(f\"üîç Primary Risk Factor: {top_feature} (Importance: {top_importance:.3f})\")\n",
    "    \n",
    "    # Fire risk assessment\n",
    "    high_risk_pixels = np.sum(fire_probability_map > 0.7)\n",
    "    medium_risk_pixels = np.sum((fire_probability_map > 0.4) & (fire_probability_map <= 0.7))\n",
    "    low_risk_pixels = np.sum(fire_probability_map <= 0.4)\n",
    "    \n",
    "    total_valid_pixels = high_risk_pixels + medium_risk_pixels + low_risk_pixels\n",
    "    \n",
    "    if total_valid_pixels > 0:\n",
    "        print(f\"üö® High Risk Areas: {high_risk_pixels:,} pixels ({high_risk_pixels/total_valid_pixels*100:.1f}%)\")\n",
    "        print(f\"‚ö†Ô∏è  Medium Risk Areas: {medium_risk_pixels:,} pixels ({medium_risk_pixels/total_valid_pixels*100:.1f}%)\")\n",
    "        print(f\"‚úÖ Low Risk Areas: {low_risk_pixels:,} pixels ({low_risk_pixels/total_valid_pixels*100:.1f}%)\")\n",
    "    \n",
    "    print()\n",
    "    print(\"üìã RECOMMENDATIONS:\")\n",
    "    print(\"‚Ä¢ Focus monitoring on high-risk areas identified by the model\")\n",
    "    print(\"‚Ä¢ Pay special attention to areas with high\", top_feature, \"values\")\n",
    "    print(\"‚Ä¢ Use fire spread simulations for emergency response planning\")\n",
    "    print(\"‚Ä¢ Regularly update model with new data for improved accuracy\")\n",
    "    print(\"‚Ä¢ Consider seasonal variations in fire risk assessment\")\n",
    "    print()\n",
    "    \n",
    "    # ============================================================================\n",
    "    # 9. SYSTEM STATUS AND NEXT STEPS\n",
    "    # ============================================================================\n",
    "    print(\"üöÄ SYSTEM STATUS AND NEXT STEPS\")\n",
    "    print(\"=\" * 40)\n",
    "    print(\"‚úÖ System Status: FULLY OPERATIONAL\")\n",
    "    print(\"‚úÖ All Components: SUCCESSFULLY COMPLETED\")\n",
    "    print(\"‚úÖ Output Files: GENERATED AND SAVED\")\n",
    "    print(\"‚úÖ Model: TRAINED AND READY FOR USE\")\n",
    "    print()\n",
    "    print(\"üéØ Next Steps:\")\n",
    "    print(\"1. Review the generated visualizations and maps\")\n",
    "    print(\"2. Analyze the output files for detailed insights\")\n",
    "    print(\"3. Use the trained model for real-time predictions\")\n",
    "    print(\"4. Implement the system for operational use\")\n",
    "    print(\"5. Schedule regular model updates with new data\")\n",
    "    print()\n",
    "    \n",
    "    print(\"üî•\" * 50)\n",
    "    print(\"üéâ FOREST FIRE PREDICTION SYSTEM COMPLETE! üéâ\")\n",
    "    print(\"üî•\" * 50)\n",
    "    \n",
    "    return {\n",
    "        'total_pixels': total_pixels,\n",
    "        'fire_pixels': fire_pixels,\n",
    "        'fire_rate': fire_rate,\n",
    "        'model_performance': performance_rating,\n",
    "        'top_feature': top_feature,\n",
    "        'high_risk_pixels': high_risk_pixels,\n",
    "        'output_files_count': len([f for f, _ in output_files if os.path.exists(f'output/{f}')])\n",
    "    }\n",
    "\n",
    "# Execute the comprehensive summary\n",
    "print(\"üîÑ Generating comprehensive summary...\")\n",
    "print(\"üî•\" * 50)\n",
    "print(\"üéØ COMPREHENSIVE FOREST FIRE PREDICTION SUMMARY üéØ\")\n",
    "print(\"üî•\" * 50)\n",
    "\n",
    "# System Configuration\n",
    "print(\"\\n‚öôÔ∏è  SYSTEM CONFIGURATION\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üìä Model Training Mode: {'NEW MODEL TRAINED' if RETRAIN_MODEL else 'EXISTING MODEL LOADED'}\")\n",
    "print(f\"üìÅ Model Path: {MODEL_PATH}\")\n",
    "print(f\"üóÇÔ∏è  Data Dimensions: {height}x{width} pixels\")\n",
    "print(f\"üìà Total Features: {len(feature_names)}\")\n",
    "print(f\"üéØ Feature List: {', '.join(feature_names)}\")\n",
    "\n",
    "# Dataset Statistics\n",
    "print(\"\\nüìä DATASET STATISTICS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üåç Total Pixels: {labels.size:,}\")\n",
    "print(f\"üî• Fire Pixels: {int(labels.sum()):,}\")\n",
    "print(f\"üìà Fire Occurrence Rate: {labels.mean()*100:.2f}%\")\n",
    "print(f\"üå°Ô∏è  Temperature Range: {realistic_data['temperature'].min():.1f}¬∞C to {realistic_data['temperature'].max():.1f}¬∞C\")\n",
    "print(f\"üíß Humidity Range: {realistic_data['humidity'].min():.1f}% to {realistic_data['humidity'].max():.1f}%\")\n",
    "print(f\"üí® Wind Speed Range: {realistic_data['wind_speed'].min():.1f} to {realistic_data['wind_speed'].max():.1f} m/s\")\n",
    "print(f\"üåßÔ∏è  Rainfall Range: {realistic_data['rainfall'].min():.1f} to {realistic_data['rainfall'].max():.1f} mm\")\n",
    "\n",
    "# Model Performance\n",
    "print(\"\\nüéØ MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\" * 40)\n",
    "for _, row in metrics_df.iterrows():\n",
    "    print(f\"üìä {row['Metric']}: {row['Value']:.4f}\")\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\nüî¨ TOP 5 MOST IMPORTANT FEATURES\")\n",
    "print(\"=\" * 40)\n",
    "for i, (_, row) in enumerate(feature_importance_df.head().iterrows(), 1):\n",
    "    print(f\"{i}. {row['Feature'].replace('_', ' ').title()}: {row['Importance']:.4f}\")\n",
    "\n",
    "# Fire Spread Simulation\n",
    "print(\"\\nüî• FIRE SPREAD SIMULATION RESULTS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üìà Total Time Steps: {len(spread_maps)}\")\n",
    "for time_step, spread_map in spread_maps.items():\n",
    "    spread_percentage = (spread_map > 0).sum() / spread_map.size * 100\n",
    "    print(f\"‚è±Ô∏è  {time_step}: {spread_percentage:.2f}% area affected\")\n",
    "\n",
    "# Custom Scenarios\n",
    "print(\"\\nüé≠ CUSTOM SCENARIOS GENERATED\")\n",
    "print(\"=\" * 40)\n",
    "for scenario_name, scenario_data in scenario_datasets.items():\n",
    "    fire_rate = scenario_data['fire_labels'].mean() * 100\n",
    "    print(f\"üåü {scenario_name.replace('_', ' ').title()}: {fire_rate:.2f}% fire rate\")\n",
    "\n",
    "# Output Files\n",
    "print(\"\\nüìÅ GENERATED OUTPUT FILES\")\n",
    "print(\"=\" * 40)\n",
    "output_files = [\n",
    "    'fire_prediction.tif',\n",
    "    'fire_probability.tif',\n",
    "    'fire_spread_1h.tif',\n",
    "    'fire_spread_2h.tif',\n",
    "    'fire_spread_3h.tif',\n",
    "    'fire_spread_6h.tif',\n",
    "    'fire_spread_12h.tif',\n",
    "    'model_report.csv',\n",
    "    'correlation_matrix.csv',\n",
    "    'fire_conditions_summary.csv',\n",
    "    'comprehensive_results.png',\n",
    "    'fire_spread_animation.gif'\n",
    "]\n",
    "\n",
    "for file in output_files:\n",
    "    filepath = f'output/{file}'\n",
    "    if os.path.exists(filepath):\n",
    "        file_size = os.path.getsize(filepath) / 1024  # KB\n",
    "        print(f\"‚úÖ {file} ({file_size:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"‚ùå {file} (not found)\")\n",
    "\n",
    "# Summary Statistics\n",
    "print(\"\\nüìä PREDICTION SUMMARY STATISTICS\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"üéØ Prediction Map - Min: {prediction_map.min():.2f}, Max: {prediction_map.max():.2f}, Mean: {prediction_map.mean():.2f}\")\n",
    "print(f\"üî• Probability Map - Min: {fire_probability_map.min():.2f}, Max: {fire_probability_map.max():.2f}, Mean: {fire_probability_map.mean():.2f}\")\n",
    "\n",
    "# Create a comprehensive results dictionary\n",
    "summary_results = {\n",
    "    'system_config': {\n",
    "        'model_trained': RETRAIN_MODEL,\n",
    "        'model_path': MODEL_PATH,\n",
    "        'data_dimensions': f\"{height}x{width}\",\n",
    "        'total_features': len(feature_names),\n",
    "        'features': feature_names\n",
    "    },\n",
    "    'dataset_stats': {\n",
    "        'total_pixels': labels.size,\n",
    "        'fire_pixels': int(labels.sum()),\n",
    "        'fire_rate': labels.mean() * 100,\n",
    "        'temp_range': [realistic_data['temperature'].min(), realistic_data['temperature'].max()],\n",
    "        'humidity_range': [realistic_data['humidity'].min(), realistic_data['humidity'].max()],\n",
    "        'wind_range': [realistic_data['wind_speed'].min(), realistic_data['wind_speed'].max()],\n",
    "        'rainfall_range': [realistic_data['rainfall'].min(), realistic_data['rainfall'].max()]\n",
    "    },\n",
    "    'model_performance': {\n",
    "        'accuracy': metrics_df[metrics_df['Metric'] == 'Accuracy']['Value'].iloc[0],\n",
    "        'precision': metrics_df[metrics_df['Metric'] == 'Precision']['Value'].iloc[0],\n",
    "        'recall': metrics_df[metrics_df['Metric'] == 'Recall']['Value'].iloc[0],\n",
    "        'f1_score': metrics_df[metrics_df['Metric'] == 'F1-Score']['Value'].iloc[0]\n",
    "    },\n",
    "    'feature_importance': feature_importance_df.head().to_dict('records'),\n",
    "    'fire_spread': {time: (spread_map > 0).sum() / spread_map.size * 100 for time, spread_map in spread_maps.items()},\n",
    "    'scenarios': {name: data['fire_labels'].mean() * 100 for name, data in scenario_datasets.items()},\n",
    "    'output_files': [f for f in output_files if os.path.exists(f'output/{f}')],\n",
    "    'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "# Save summary as JSON (no Unicode issues)\n",
    "import json\n",
    "with open('output/system_summary.json', 'w') as f:\n",
    "    json.dump(summary_results, f, indent=2, default=str)\n",
    "\n",
    "# Create a text summary without Unicode emojis\n",
    "summary_text = f\"\"\"\n",
    "FOREST FIRE PREDICTION SYSTEM - EXECUTION SUMMARY\n",
    "=================================================\n",
    "\n",
    "SYSTEM CONFIGURATION:\n",
    "- Model Training: {'NEW MODEL TRAINED' if RETRAIN_MODEL else 'EXISTING MODEL LOADED'}\n",
    "- Model Path: {MODEL_PATH}\n",
    "- Data Dimensions: {height}x{width} pixels\n",
    "- Features: {len(feature_names)}\n",
    "\n",
    "DATASET STATISTICS:\n",
    "- Total Pixels: {labels.size:,}\n",
    "- Fire Pixels: {int(labels.sum()):,}\n",
    "- Fire Rate: {labels.mean()*100:.2f}%\n",
    "- Temperature: {realistic_data['temperature'].min():.1f}¬∞C to {realistic_data['temperature'].max():.1f}¬∞C\n",
    "\n",
    "MODEL PERFORMANCE:\n",
    "- Accuracy: {metrics_df[metrics_df['Metric'] == 'Accuracy']['Value'].iloc[0]:.4f}\n",
    "- Precision: {metrics_df[metrics_df['Metric'] == 'Precision']['Value'].iloc[0]:.4f}\n",
    "- Recall: {metrics_df[metrics_df['Metric'] == 'Recall']['Value'].iloc[0]:.4f}\n",
    "- F1-Score: {metrics_df[metrics_df['Metric'] == 'F1-Score']['Value'].iloc[0]:.4f}\n",
    "\n",
    "FIRE SPREAD SIMULATION:\n",
    "- Time Steps: {len(spread_maps)}\n",
    "- Coverage per time step: {', '.join([f'{k}: {(v > 0).sum() / v.size * 100:.1f}%' for k, v in spread_maps.items()])}\n",
    "\n",
    "OUTPUT FILES: {len([f for f in output_files if os.path.exists(f'output/{f}')])} files generated\n",
    "\n",
    "Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "with open('output/system_summary.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"\\nüìÑ Complete summary saved to: output/system_summary.txt\")\n",
    "print(\"üìÑ Detailed summary saved to: output/system_summary.json\")\n",
    "print(\"üéØ All important outputs have been consolidated!\")\n",
    "\n",
    "print(\"\\nüî•\" * 50)\n",
    "print(\"üéâ FOREST FIRE PREDICTION SYSTEM COMPLETE! üéâ\")\n",
    "print(\"üî•\" * 50)\n",
    "\n",
    "# Display key results visually\n",
    "print(\"\\nüéØ QUICK RESULTS OVERVIEW:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model Accuracy: {metrics_df[metrics_df['Metric'] == 'Accuracy']['Value'].iloc[0]:.2%}\")\n",
    "print(f\"Fire Coverage: {labels.mean():.2%} of total area\")\n",
    "print(f\"Output Files: {len([f for f in output_files if os.path.exists(f'output/{f}')])} files created\")\n",
    "print(f\"Scenarios: {len(scenario_datasets)} different fire scenarios\")\n",
    "print(f\"Spread Steps: {len(spread_maps)} time predictions\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dfed1a",
   "metadata": {},
   "source": [
    "# üìä COMPREHENSIVE FOREST FIRE PREDICTION SUMMARY\n",
    "\n",
    "This section provides a complete summary of all analysis results, model performance, and key findings from the forest fire prediction pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f465d289",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üî• FOREST FIRE PREDICTION - COMPREHENSIVE ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# System Configuration\n",
    "print(\"\\nüìã SYSTEM CONFIGURATION:\")\n",
    "print(f\"   Model Training: {'New model trained' if RETRAIN_MODEL else 'Existing model loaded'}\")\n",
    "print(f\"   Model Path: {MODEL_PATH}\")\n",
    "print(f\"   Force Retrain: {FORCE_RETRAIN}\")\n",
    "\n",
    "# Dataset Overview\n",
    "print(\"\\nüìä DATASET OVERVIEW:\")\n",
    "print(f\"   Total samples: {len(X):,}\")\n",
    "print(f\"   Features: {len(feature_names)}\")\n",
    "print(f\"   Data shape: {X.shape}\")\n",
    "print(f\"   Fire pixels: {np.sum(y == 1):,} ({np.sum(y == 1)/len(y)*100:.1f}%)\")\n",
    "print(f\"   Non-fire pixels: {np.sum(y == 0):,} ({np.sum(y == 0)/len(y)*100:.1f}%)\")\n",
    "\n",
    "# Feature Information\n",
    "print(\"\\nüîç FEATURE INFORMATION:\")\n",
    "for i, feature in enumerate(feature_names):\n",
    "    print(f\"   {i+1}. {feature}\")\n",
    "\n",
    "# Model Performance\n",
    "print(\"\\nüéØ MODEL PERFORMANCE:\")\n",
    "if 'metrics_df' in locals():\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "        if metric in metrics_df.columns:\n",
    "            value = metrics_df[metric].iloc[0]\n",
    "            print(f\"   {metric.capitalize()}: {value:.4f}\")\n",
    "\n",
    "# Feature Importance\n",
    "print(\"\\n‚≠ê TOP 10 MOST IMPORTANT FEATURES:\")\n",
    "if 'feature_importance_df' in locals():\n",
    "    top_features = feature_importance_df.head(10)\n",
    "    for idx, row in top_features.iterrows():\n",
    "        print(f\"   {idx+1}. {row['feature']}: {row['importance']:.4f}\")\n",
    "\n",
    "# Fire Conditions Summary\n",
    "print(\"\\nüå°Ô∏è FIRE CONDITIONS ANALYSIS:\")\n",
    "if 'conditions_summary' in locals():\n",
    "    print(\"   High Risk Conditions:\")\n",
    "    for condition in ['High Temperature', 'Low Humidity', 'High Wind Speed']:\n",
    "        if condition in conditions_summary.index:\n",
    "            value = conditions_summary.loc[condition, 'percentage']\n",
    "            print(f\"   - {condition}: {value:.1f}% of area\")\n",
    "\n",
    "# Scenario Analysis Results\n",
    "print(\"\\nüé≠ SCENARIO ANALYSIS RESULTS:\")\n",
    "if 'scenario_datasets' in locals():\n",
    "    for scenario_name in scenario_datasets.keys():\n",
    "        print(f\"   ‚úì {scenario_name.replace('_', ' ').title()} - Analysis completed\")\n",
    "\n",
    "# Fire Spread Simulation\n",
    "print(\"\\nüîÑ FIRE SPREAD SIMULATION:\")\n",
    "if 'spread_maps' in locals():\n",
    "    print(\"   Time intervals analyzed:\")\n",
    "    for time_interval in sorted(spread_maps.keys()):\n",
    "        spread_area = np.sum(spread_maps[time_interval] > 0)\n",
    "        print(f\"   - {time_interval}: {spread_area:,} pixels affected\")\n",
    "\n",
    "# Output Files Generated\n",
    "print(\"\\nüìÅ OUTPUT FILES GENERATED:\")\n",
    "output_files = [\n",
    "    'fire_prediction.tif',\n",
    "    'fire_probability.tif', \n",
    "    'correlation_matrix.csv',\n",
    "    'model_report.csv',\n",
    "    'fire_conditions_summary.csv',\n",
    "    'comprehensive_results.png',\n",
    "    'fire_spread_animation.gif'\n",
    "]\n",
    "\n",
    "for file in output_files:\n",
    "    file_path = f\"output/{file}\"\n",
    "    if os.path.exists(file_path):\n",
    "        size = os.path.getsize(file_path)\n",
    "        print(f\"   ‚úì {file} ({size:,} bytes)\")\n",
    "    else:\n",
    "        print(f\"   ‚úó {file} (not found)\")\n",
    "\n",
    "# Spread simulation files\n",
    "for time_interval in ['1h', '2h', '3h', '6h', '12h']:\n",
    "    file_path = f\"output/fire_spread_{time_interval}.tif\"\n",
    "    if os.path.exists(file_path):\n",
    "        size = os.path.getsize(file_path)\n",
    "        print(f\"   ‚úì fire_spread_{time_interval}.tif ({size:,} bytes)\")\n",
    "\n",
    "# Key Statistics\n",
    "print(\"\\nüìà KEY STATISTICS:\")\n",
    "if 'fire_probability_map' in locals():\n",
    "    print(f\"   Average fire probability: {np.mean(fire_probability_map):.4f}\")\n",
    "    print(f\"   Maximum fire probability: {np.max(fire_probability_map):.4f}\")\n",
    "    print(f\"   High risk areas (>0.7): {np.sum(fire_probability_map > 0.7):,} pixels\")\n",
    "\n",
    "if 'prediction_map' in locals():\n",
    "    predicted_fire = np.sum(prediction_map == 1)\n",
    "    total_pixels = np.sum(prediction_map >= 0)\n",
    "    print(f\"   Predicted fire pixels: {predicted_fire:,} ({predicted_fire/total_pixels*100:.1f}%)\")\n",
    "\n",
    "# Correlation Insights\n",
    "print(\"\\nüîó CORRELATION INSIGHTS:\")\n",
    "if 'correlation_matrix' in locals():\n",
    "    # Find strongest correlations with fire_labels\n",
    "    if 'fire_labels' in correlation_matrix.columns:\n",
    "        fire_correlations = correlation_matrix['fire_labels'].abs().sort_values(ascending=False)\n",
    "        print(\"   Strongest correlations with fire occurrence:\")\n",
    "        for feature, corr in fire_correlations.head(5).items():\n",
    "            if feature != 'fire_labels':\n",
    "                print(f\"   - {feature}: {corr:.3f}\")\n",
    "\n",
    "# Recommendations\n",
    "print(\"\\nüí° KEY RECOMMENDATIONS:\")\n",
    "print(\"   1. Focus monitoring on high-risk areas identified by the model\")\n",
    "print(\"   2. Pay special attention to areas with high temperature and low humidity\")\n",
    "print(\"   3. Consider wind patterns for fire spread prediction\")\n",
    "print(\"   4. Use scenario analysis for emergency planning\")\n",
    "print(\"   5. Regularly update the model with new data\")\n",
    "\n",
    "# Data Quality Assessment\n",
    "print(\"\\n‚úÖ DATA QUALITY ASSESSMENT:\")\n",
    "total_features = len(feature_names)\n",
    "print(f\"   Features processed: {total_features}/10 expected\")\n",
    "print(f\"   Data completeness: {(1 - np.isnan(X).sum()/X.size)*100:.1f}%\")\n",
    "print(f\"   Model training: {'‚úì Successful' if 'fire_model' in locals() else '‚úó Failed'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ ANALYSIS COMPLETE - All results saved to output/ directory\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save summary to file\n",
    "summary_text = f\"\"\"\n",
    "FOREST FIRE PREDICTION ANALYSIS SUMMARY\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "SYSTEM CONFIGURATION:\n",
    "- Model Training: {'New model trained' if RETRAIN_MODEL else 'Existing model loaded'}\n",
    "- Model Path: {MODEL_PATH}\n",
    "\n",
    "DATASET OVERVIEW:\n",
    "- Total samples: {len(X):,}\n",
    "- Features: {len(feature_names)}\n",
    "- Fire pixels: {np.sum(y == 1):,} ({np.sum(y == 1)/len(y)*100:.1f}%)\n",
    "- Non-fire pixels: {np.sum(y == 0):,} ({np.sum(y == 0)/len(y)*100:.1f}%)\n",
    "\n",
    "MODEL PERFORMANCE:\n",
    "\"\"\"\n",
    "\n",
    "if 'metrics_df' in locals():\n",
    "    for metric in ['accuracy', 'precision', 'recall', 'f1']:\n",
    "        if metric in metrics_df.columns:\n",
    "            value = metrics_df[metric].iloc[0]\n",
    "            summary_text += f\"- {metric.capitalize()}: {value:.4f}\\n\"\n",
    "\n",
    "summary_text += f\"\"\"\n",
    "TOP FEATURES:\n",
    "\"\"\"\n",
    "if 'feature_importance_df' in locals():\n",
    "    for idx, row in feature_importance_df.head(5).iterrows():\n",
    "        summary_text += f\"- {row['feature']}: {row['importance']:.4f}\\n\"\n",
    "\n",
    "summary_text += f\"\"\"\n",
    "KEY STATISTICS:\n",
    "- Average fire probability: {np.mean(fire_probability_map):.4f}\n",
    "- High risk areas (>0.7): {np.sum(fire_probability_map > 0.7):,} pixels\n",
    "- Predicted fire pixels: {np.sum(prediction_map == 1):,}\n",
    "\n",
    "ANALYSIS COMPLETE\n",
    "\"\"\"\n",
    "\n",
    "with open('output/analysis_summary.txt', 'w') as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"\\nüìÑ Summary also saved to: output/analysis_summary.txt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
